{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSION "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### METHODES : \n",
    "\n",
    "Travail attendu = regression \n",
    "\n",
    "Meilleures performances = Classification\n",
    "\n",
    "Modèles à tester : \n",
    " - regression lineaire \n",
    " - regression polynomiale\n",
    " - Regression logistique \n",
    "\n",
    "\n",
    "### Inspi\n",
    "- https://www.kaggle.com/code/ecedolen/classification-logistic-regression-wine-quality\n",
    "- https://www.kaggle.com/code/abolarinbukola/logistic-regression-wine-quality-92\n",
    "-https://www.kaggle.com/code/madhurisivalenka/basic-machine-learning-with-red-wine-quality-data\n",
    "- Lême si l'objectif est d efaire de la regresison ==> Completer la classif avec un randomforest et SVC : https://www.kaggle.com/code/madhurisivalenka/basic-machine-learning-with-red-wine-quality-data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des données "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-traitement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='density', y='alcohol', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING POLYNOPMIALE AND LINEAR REGRESSION "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['quality']]\n",
    "y = df[['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Regression polynomiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PolynomialFeatures(degree= 4)\n",
    "y_ = model.fit_transform(y)\n",
    "y_test_ = model.fit_transform(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression lineaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "print(lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = lm.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "\n",
    "#print confusion matrix and accuracy score\n",
    "lm_conf_matrix = confusion_matrix(y_test, predicted_data)\n",
    "lm_acc_score = accuracy_score(y_test, predicted_data)\n",
    "print(lm_conf_matrix)\n",
    "print(lm_acc_score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R sq: ',lm.score(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlation: ', math.sqrt(lm.score(x_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = lm.predict(x_test)\n",
    "\n",
    "plt.title('Comparison of Y values in test and the Predicted values')\n",
    "plt.ylabel('Test Set')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.scatter(y_predicted, y_test,  color='black')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING LOGISTIC REGRESSION "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bins.type = df_bins.type.map({'white':0, 'red':1})\n",
    "\n",
    "X = df_bins[['type', 'alcohol', 'density', 'volatile_acidity', 'chlorides',\n",
    "       'citric_acid', 'fixed_acidity', 'free_sulfur_dioxide',\n",
    "       'total_sulfur_dioxide', 'sulphates', 'residual_sugar', 'pH']] \n",
    "y = df_bins.quality_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=40)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = lr.score(X_train, y_train)\n",
    "test_accuracy = lr.score(X_test, y_test)\n",
    "print('One-vs-rest', '-'*35, \n",
    "      'Accuracy in Train Group   : {:.2f}'.format(train_accuracy), \n",
    "      'Accuracy in Test  Group   : {:.2f}'.format(test_accuracy), sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X_test)\n",
    "score = round(accuracy_score(y_test, predictions), 3)\n",
    "cm1 = cm(y_test, predictions)\n",
    "sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test  = lr.predict(X_test)\n",
    "pred_train = lr.predict(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performances \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_pred = LogisticRegression(random_state=40)\n",
    "quality_pred.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_train = confusion_matrix(y_train,pred_train)\n",
    "confusion_matrix_test = confusion_matrix(y_test,pred_test)\n",
    "\n",
    "print('Confusion Matrix Train Data', '--'*20, confusion_matrix_train, sep='\\n')\n",
    "print('Confusion Matrix Test Data', '--'*20, confusion_matrix_test, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = confusion_matrix_test[0][0]\n",
    "TP = confusion_matrix_test[1][1]\n",
    "FP = confusion_matrix_test[0][1]\n",
    "FN = confusion_matrix_test[1][0]\n",
    "\n",
    "print(\"(Total) True Negative       :\", TN)\n",
    "print(\"(Total) True Positive       :\", TP)\n",
    "print(\"(Total) Negative Positive   :\", FP)\n",
    "print(\"(Total) Negative Negative   :\", FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ACCURACY \n",
    "print(\"Accuracy Score of Our Model     : \",  quality_pred.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Error Rate\n",
    "Error_Rate = 1- (accuracy_score(y_test, pred_test))  \n",
    "Error_Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Precision\n",
    "print(\"precision_score:\",  precision_score(y_test, pred_test, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Recall\n",
    "print(\"recall_score: \",  recall_score(y_test, pred_test, average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Specificity\n",
    "print(\" Specificity Score : \", (TN)/(TN + FP)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### F1 score\n",
    "precision_s = precision_score(y_test, pred_test,average='micro')\n",
    "recall_s    = recall_score(y_test, pred_test, average='micro')\n",
    "\n",
    "print(\"F1_score : \",  2*((precision_s*recall_s)/(precision_s + recall_s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "print(classification_report(y_test,pred_test))\n",
    "\n",
    "print(\"f1_score        : {:.2f}\".format(f1_score(y_test, pred_test, average='micro')))\n",
    "print(\"recall_score    : {:.2f}\".format(recall_score(y_test, pred_test, average='micro')))\n",
    "print(\"precision_score : {:.2f}\".format(precision_score(y_test, pred_test, average='micro')))\n",
    "\n",
    "print('\\n')\n",
    "metrics =  precision_recall_fscore_support(y_test, pred_test)\n",
    "print(\"Precision       :\" , metrics[0]) \n",
    "#print(\"Recall          :\" , metrics[1]) \n",
    "print(\"F1 Score        :\" , metrics[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ROC/AUC(Area Under Curve)\n",
    "probs = quality_pred.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds  = roc_curve(y_test, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate = 1 - Specificity Score')\n",
    "plt.ylabel('True Positive Rate  = Recall Score')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRECISION RECALL CURVE\n",
    "precision, recall, _ = precision_recall_curve(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recall, precision)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Log Loss\n",
    "print(\"Log-Loss) : \" , log_loss(y_test.values, probs))\n",
    "print(\"Error Rate : \" , 1- accuracy_score(y_test.values, pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "404d4b4449c415f353872e970a2782c513d076429a61a6054f5f7db0dbede263"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
